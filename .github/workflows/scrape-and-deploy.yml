# this workflow scrapes concerts every monday at 12am pacific time (8am utc) and pushes changes to trigger cloudflare pages
name: scrape and deploy

on:
  schedule:
    - cron: "0 7 * * 1" # every monday at 12am pacific (8am utc)
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      # checkout your repo
      - name: checkout repo
        uses: actions/checkout@v4

      # setup node
      - name: setup node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      # install dependencies
      - name: install dependencies
        run: npm ci

      # run the scraper and wait for completion
      - name: run scraper
        run: node scripts/scrape-concerts.js

      # process databases from scraped data
      - name: process databases
        run: node scripts/process-databases.js

      # commit and push changes if any
      - name: commit and push
        env:
          GITHUB_TOKEN: ${{ secrets.SECRET_PUNK }}
        run: |
          git config --local user.email "${{ github.actor }}@users.noreply.github.com"
          git config --local user.name "${{ github.actor }}"
          git add src/data/
          git commit -m "auto: update concerts data and processed databases $(date -u '+%Y-%m-%d %H:%M UTC')" || echo "no changes to commit"
          git push
